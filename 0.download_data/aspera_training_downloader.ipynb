{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspera Training Movie Downloader\n",
    "### Download training movies from IDR using the Aspera high-speed transfer client\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Labeled Data\n",
    "Save plate/well of feature data to `training_locations.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read plates listed in features dataset to figure out which wells from which plates have labeled data\n",
    "#Save these training locations into a file\n",
    "\n",
    "def save_training_wells(features_path, save_path):\n",
    "    data_list = []\n",
    "    with open(\"trainingset.dat\") as labels_file:\n",
    "        for line in labels_file:\n",
    "            if \".tif\" in line: #look at lines with plates/wells\n",
    "                plate = re.search('(.*)--W00', line).group(1)\n",
    "                well = re.search('--W00(.*)--P0', line).group(1)\n",
    "                if [plate, well] not in data_list:\n",
    "                    data_list.append([plate, well])\n",
    "    dataframe = pd.DataFrame(data_list, columns=['Plate', 'Well'])\n",
    "    dataframe.to_csv(save_path, sep=\"\\t\")\n",
    "    \n",
    "features_path = \"training_set/features/\"\n",
    "save_path = \"training_locations.tsv\"\n",
    "save_training_wells(features_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download movies that have labels\n",
    "Use Aspera to download wells listed in `training_locations.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0043_48/166'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0017_19/365'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0064_14/003'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0042_10/044'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0042_10/144'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0096_33/255'\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0030_17/184'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0101_01/277'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0144_01/166'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0094_44/319'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0023_04/005'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0038_01/245'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0014_12/159'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0028_14/129'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0084_46/003'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0066_19/287'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0027_44/030'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0027_44/292'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0067_02/099'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0093_17/114'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0038_27/250'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0065_06/054'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0026_22/258'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0109_38/349'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0109_38/338'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0109_38/381'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0089_01/175'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0105_04/144'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0132_31/053'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0066_23/163'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0048_14/335'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0098_13/021'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0039_45/136'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0013_38/042'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0041_32/132'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0038_08/250'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0157_04/005'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0065_04/020'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0013_42/107'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0094_01/319'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0100_03/093'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0044_36/249'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0035_06/274'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0047_27/140'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0046_19/356'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0093_13/147'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0138_03/127'\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0094_04/319'\n",
      "can only convert an array of size 1 to a Python scalar\n",
      "[Errno 17] File exists: 'labeled_movies_ch5/LT0090_33/383'\n",
      "sudo /home/roshankern/.aspera/ascli/sdk/ascp -TQ -l500m -P 33001 -i asperaweb_id_dsa.openssh idr0013@fasp.ebi.ac.uk:20150916-mitocheck-analysis/mitocheck/LT0106_02--ex2005_12_07--sp2005_08_22--tt17--c3/hdf5/00287_01.ch5 labeled_movies_ch5/LT0106_02/287\n",
      "Completed: 48564K bytes transferred in 2 seconds\n",
      " (171624K bits/sec), in 1 file.\n"
     ]
    }
   ],
   "source": [
    "def download_labeled_data(training_locations_path, screens_path, aspera_path, key_path, download_path):\n",
    "    training_locations = pd.read_csv(training_locations_path, sep=\"\\t\")\n",
    "    screens = pd.read_csv(screens_path, sep=\"\\t\", header=None)\n",
    "    screens.columns = [\"Plate\", \"Screen\"]\n",
    "    \n",
    "    #download each well from IDR, if it is available on IDR\n",
    "    for index, row in training_locations.iterrows():\n",
    "        try:\n",
    "            #example command: \n",
    "            \"\"\"sudo /home/roshankern/.aspera/ascli/sdk/ascp\n",
    "            -TQ -l500m -P 33001 -i /home/roshankern/Desktop/aspera/asperaweb_\n",
    "            id_dsa.openssh idr0013@fasp.ebi.ac.uk:20150916-mitocheck-analysis/mitocheck/LT0001_02--ex2005_11_16--sp2005_02_17--tt17--c3/hdf5/00002_01.ch5 \n",
    "            0.download_data/labeled_movies_ch5/\"\"\"\n",
    "            \n",
    "            #get location of screen\n",
    "            screen_loc = screens.loc[screens['Plate'] == row['Plate'], 'Screen'].item().replace(\"../screens/\", \"\").replace(\".screen\", \"\")\n",
    "            \n",
    "            well_path = \"20150916-mitocheck-analysis/mitocheck/\" + screen_loc + \"/hdf5/00\" + \"{:03d}\".format(row['Well']) + \"_01.ch5\"\n",
    "            idr_location = \"idr0013@fasp.ebi.ac.uk:\" + well_path + \" \"\n",
    "            \n",
    "            os.makedirs(download_path + row['Plate'] + \"/\" + \"{:03d}\".format(row['Well']))\n",
    "            command = \"sudo \" + aspera_path + \" -TQ -l500m -P 33001 -i \" + key_path + \" \" + idr_location + download_path + row['Plate'] + \"/\" + \"{:03d}\".format(row['Well'])\n",
    "            print(command)\n",
    "            os.system(command)\n",
    "        except Exception as e: #some plates are not available on IDR\n",
    "            print(e)\n",
    "\n",
    "\n",
    "aspera_path = \"/home/roshankern/.aspera/ascli/sdk/ascp\"\n",
    "key_path = \"asperaweb_id_dsa.openssh\"\n",
    "os.makedirs(\"labeled_movies_ch5/\", exist_ok=True)\n",
    "download_path = \"labeled_movies_ch5/\"\n",
    "\n",
    "training_locations_path = \"training_locations.tsv\"\n",
    "screens_path = \"idr0013-screenA-plates.tsv\"\n",
    "\n",
    "download_labeled_data(training_locations_path, screens_path, aspera_path, key_path, download_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mitocheck_data2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0971d304d530f8782ddf884fa144d2d323dae9a36a62ac6f739c483391c02eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
