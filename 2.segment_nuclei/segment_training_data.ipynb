{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cellpose.io import logger_setup\n",
    "from cellpose import models, core, io, utils\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Segmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_features_file(features_path, plate, well, frame):\n",
    "    movie_path = pathlib.Path(f\"{features_path}/{plate}/features/{well}/\")\n",
    "    frame_time = (int(frame)-1)*30\n",
    "    frame_time_string = f\"T{str(frame_time).zfill(5)}\"\n",
    "    \n",
    "    for frame_file in movie_path.iterdir():\n",
    "        if(frame_time_string in frame_file.name):\n",
    "            return frame_file\n",
    "\n",
    "def get_frame_labels(training_set_dat_path, plate, well, frame):\n",
    "    well_string = f\"W{str(well).zfill(5)}\"\n",
    "    frame_time = (int(frame)-1)*30\n",
    "    frame_time_string = f\"T{str(frame_time).zfill(5)}\"\n",
    "    frame_file_details = [plate, well_string, frame_time_string]\n",
    "    \n",
    "    frame_objects = []\n",
    "    with open(training_set_dat_path) as trainingset_file:\n",
    "        append = False\n",
    "        for line in trainingset_file:\n",
    "            if append and \".tif\" in line:\n",
    "                append = False\n",
    "            if append:\n",
    "                object_details = line.strip().split(\": \")\n",
    "                frame_objects.append(object_details)\n",
    "            #match plate, well, frame to file name\n",
    "            if all(detail in line for detail in frame_file_details):\n",
    "                print(line.strip()) #starting line for movie labels\n",
    "                append = True\n",
    "    return frame_objects\n",
    "\n",
    "def is_labeled(centroid, frame_features, frame_labels):\n",
    "    \"\"\"\n",
    "    returns true if nucleus is included in labeled training data, false if not\n",
    "    \"\"\"\n",
    "    objID = -1\n",
    "    labeled = False\n",
    "        \n",
    "    #determine if centroid is inside any of labeled bounding boxes\n",
    "    x = centroid[0]\n",
    "    y = centroid[1]\n",
    "    for labels in frame_labels:\n",
    "        labeled_feature = frame_features[frame_features[0] == int(labels[0])]\n",
    "        upperLeft_x = labeled_feature.iloc[0][1]\n",
    "        upperLeft_y = labeled_feature.iloc[0][2]\n",
    "        width = labeled_feature.iloc[0][3]\n",
    "        height = labeled_feature.iloc[0][4]\n",
    "        bottomRight_x = upperLeft_x + width\n",
    "        bottomRight_y = upperLeft_y + height\n",
    "        if upperLeft_x <= x and x <= bottomRight_x:\n",
    "            if y >= upperLeft_y and y <= bottomRight_y:\n",
    "                objID = labeled_feature.iloc[0][0]\n",
    "                labeled = True\n",
    "        \n",
    "    return objID, labeled\n",
    "\n",
    "def get_nuclei_locations(load_path, features_path, training_set_dat_path, cellpose_model, plate, well, frame):\n",
    "    \"\"\"\n",
    "    returns nuclei location data in CellProfiler IdentifyPrimaryObjects format as pandas dataframe\n",
    "    ie: ImageNumber, ObjectNumber, Location_Center_X, Location_Center_Y, Location_Center_Z\n",
    "    \"\"\"\n",
    "    nuclei_data = []\n",
    "    \n",
    "    #use cellpose to get nuclei outlines\n",
    "    channels = [0,0]\n",
    "    frame_image = io.imread(load_path)\n",
    "    masks, flows, styles, diams = cellpose_model.eval(frame_image, diameter=0, channels=channels, flow_threshold=0.8)\n",
    "    outlines = utils.outlines_list(masks)\n",
    "    \n",
    "    frame_features_path = get_frame_features_file(features_path, plate, well, frame)\n",
    "    print(frame_features_path)\n",
    "    frame_features = pd.read_csv(frame_features_path, compression='gzip', header=None)\n",
    "    frame_labels = get_frame_labels(training_set_dat_path, plate, well, frame)\n",
    "    for outline in outlines:\n",
    "        centroid = outline.mean(axis=0)\n",
    "        objId, cell_is_labeled = is_labeled(centroid, frame_features, frame_labels)\n",
    "        \n",
    "        if cell_is_labeled:\n",
    "            nucleus_data = {\n",
    "                        \"ImageNumber\": 1, \n",
    "                        \"ObjectNumber\": len(nuclei_data)+1,\n",
    "                        \"Location_Center_X\": centroid[0],\n",
    "                        \"Location_Center_Y\": centroid[1],\n",
    "                        \"Location_Center_Z\": 0,\n",
    "                        \"Mitocheck_Object_ID\": objId\n",
    "                        }\n",
    "            nuclei_data.append(nucleus_data)\n",
    "        \n",
    "    nuclei_data = pd.DataFrame(nuclei_data)\n",
    "    return nuclei_data\n",
    "\n",
    "def segment_training_data(preproc_training_path, features_path, training_set_dat_path, save_path, cellpose_model):\n",
    "    \"\"\"\n",
    "    saves nuclei location data in CellProfiler IdentifyPrimaryObjects format as csv file\n",
    "    ie: ImageNumber, ObjectNumber, Location_Center_X, Location_Center_Y, Location_Center_Z\n",
    "    \"\"\"\n",
    "    for plate_path in preproc_training_path.iterdir():\n",
    "        for well_path in plate_path.iterdir():\n",
    "            for frame_path in well_path.iterdir():\n",
    "                for file_path in frame_path.iterdir():\n",
    "                    segmented_save_dir = pathlib.Path(f\"{save_path}/{plate_path.name}/{well_path.name}/{frame_path.name}\")\n",
    "                    print(f\"Segmenting: {file_path}\")\n",
    "                    if segmented_save_dir.exists():\n",
    "                        print(\"Movie has already been segmented!\")\n",
    "                    else:\n",
    "                        try:\n",
    "                            nuclei_data = get_nuclei_locations(file_path, features_path, training_set_dat_path, cellpose_model, plate_path.name, well_path.name, frame_path.name)\n",
    "                            segmented_save_dir.mkdir(parents=True, exist_ok=False)\n",
    "                            nuclei_data_path = pathlib.Path(f\"{segmented_save_dir}/{plate_path.name}_{well_path.name}_{frame_path.name}.tsv\")\n",
    "                            nuclei_data.to_csv(nuclei_data_path, sep='\\t')\n",
    "                        except Exception as e:\n",
    "                            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up CellPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:54:01,485 [INFO] ** TORCH CUDA version installed and working. **\n",
      ">>> GPU activated? 1\n"
     ]
    }
   ],
   "source": [
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "#logger_setup();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment All Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:54:01,504 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2022-06-21 14:54:01,504 [INFO] >>>> using GPU\n",
      "2022-06-21 14:54:01,505 [INFO] >> cyto << model set to be used\n",
      "2022-06-21 14:54:01,598 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/48/LT0043_48_166_48.tif\n",
      "2022-06-21 14:54:01,601 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:04,332 [INFO] estimated cell diameter(s) in 2.73 sec\n",
      "2022-06-21 14:54:04,332 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:04,333 [INFO] [ 28.28 ]\n",
      "2022-06-21 14:54:04,333 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:05,258 [INFO] >>>> TOTAL TIME 3.66 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T01410--TR01475--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T01410--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/55/LT0043_48_166_55.tif\n",
      "2022-06-21 14:54:05,737 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:08,319 [INFO] estimated cell diameter(s) in 2.58 sec\n",
      "2022-06-21 14:54:08,320 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:08,320 [INFO] [ 28.33 ]\n",
      "2022-06-21 14:54:08,321 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:09,194 [INFO] >>>> TOTAL TIME 3.46 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T01620--TR01685--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T01620--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/36/LT0043_48_166_36.tif\n",
      "2022-06-21 14:54:13,282 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:16,083 [INFO] estimated cell diameter(s) in 2.80 sec\n",
      "2022-06-21 14:54:16,083 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:16,084 [INFO] [ 27.98 ]\n",
      "2022-06-21 14:54:16,084 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:16,957 [INFO] >>>> TOTAL TIME 3.68 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T01050--TR01115--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T01050--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/74/LT0043_48_166_74.tif\n",
      "2022-06-21 14:54:18,237 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:20,794 [INFO] estimated cell diameter(s) in 2.56 sec\n",
      "2022-06-21 14:54:20,794 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:20,794 [INFO] [ 28.05 ]\n",
      "2022-06-21 14:54:20,795 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:21,710 [INFO] >>>> TOTAL TIME 3.47 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T02190--TR02255--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T02190--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/44/LT0043_48_166_44.tif\n",
      "2022-06-21 14:54:24,786 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:27,510 [INFO] estimated cell diameter(s) in 2.72 sec\n",
      "2022-06-21 14:54:27,511 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:27,511 [INFO] [ 28.28 ]\n",
      "2022-06-21 14:54:27,511 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:28,453 [INFO] >>>> TOTAL TIME 3.67 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T01290--TR01355--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T01290--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/71/LT0043_48_166_71.tif\n",
      "2022-06-21 14:54:30,798 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "2022-06-21 14:54:33,368 [INFO] estimated cell diameter(s) in 2.57 sec\n",
      "2022-06-21 14:54:33,369 [INFO] >>> diameter(s) = \n",
      "2022-06-21 14:54:33,369 [INFO] [ 27.91 ]\n",
      "2022-06-21 14:54:33,369 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2022-06-21 14:54:34,297 [INFO] >>>> TOTAL TIME 3.50 sec\n",
      "features/LT0043_48/features/166/Features--W00166--P00001--T02100--TR02165--SL00001--O01--Q01--F06--A01--C00--L00--PL02--I0020.dat.gz\n",
      "LT0043_48--W00166--P00001--T02100--OGG1.tif\n",
      "Segmenting: ../1.preprocess_data/labeled_frames_preprocessed/LT0043_48/166/56/LT0043_48_166_56.tif\n",
      "2022-06-21 14:54:38,321 [INFO] ~~~ ESTIMATING CELL DIAMETER(S) ~~~\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000004?line=3'>4</a>\u001b[0m save_path \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\u001b[39m\"\u001b[39m\u001b[39msegmented/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000004?line=4'>5</a>\u001b[0m cellpose_model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mCellpose(gpu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcyto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000004?line=5'>6</a>\u001b[0m segment_training_data(load_path, features_path, training_set_dat_path, save_path, cellpose_model)\n",
      "\u001b[1;32m/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb Cell 4'\u001b[0m in \u001b[0;36msegment_training_data\u001b[0;34m(preproc_training_path, features_path, training_set_dat_path, save_path, cellpose_model)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=103'>104</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=104'>105</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=105'>106</a>\u001b[0m         nuclei_data \u001b[39m=\u001b[39m get_nuclei_locations(file_path, features_path, training_set_dat_path, cellpose_model, plate_path\u001b[39m.\u001b[39;49mname, well_path\u001b[39m.\u001b[39;49mname, frame_path\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=106'>107</a>\u001b[0m         segmented_save_dir\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=107'>108</a>\u001b[0m         nuclei_data_path \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msegmented_save_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mplate_path\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mwell_path\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mframe_path\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.tsv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_nuclei_locations\u001b[0;34m(load_path, features_path, training_set_dat_path, cellpose_model, plate, well, frame)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=63'>64</a>\u001b[0m channels \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=64'>65</a>\u001b[0m frame_image \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mimread(load_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=65'>66</a>\u001b[0m masks, flows, styles, diams \u001b[39m=\u001b[39m cellpose_model\u001b[39m.\u001b[39;49meval(frame_image, diameter\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, channels\u001b[39m=\u001b[39;49mchannels, flow_threshold\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=66'>67</a>\u001b[0m outlines \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39moutlines_list(masks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/roshankern/Desktop/Github/mitocheck_data/2.segment_nuclei/segment_training_data.ipynb#ch0000001?line=68'>69</a>\u001b[0m frame_features_path \u001b[39m=\u001b[39m get_frame_features_file(features_path, plate, well, frame)\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/models.py:215\u001b[0m, in \u001b[0;36mCellpose.eval\u001b[0;34m(self, x, batch_size, channels, channel_axis, z_axis, invert, normalize, diameter, do_3D, anisotropy, net_avg, augment, tile, tile_overlap, resample, interp, flow_threshold, cellprob_threshold, min_size, stitch_threshold, rescale, progress, model_loaded)\u001b[0m\n\u001b[1;32m    213\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    214\u001b[0m models_logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m~~~ ESTIMATING CELL DIAMETER(S) ~~~\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m diams, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msz\u001b[39m.\u001b[39;49meval(x, channels\u001b[39m=\u001b[39;49mchannels, channel_axis\u001b[39m=\u001b[39;49mchannel_axis, invert\u001b[39m=\u001b[39;49minvert, batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m    216\u001b[0m                         augment\u001b[39m=\u001b[39;49maugment, tile\u001b[39m=\u001b[39;49mtile, normalize\u001b[39m=\u001b[39;49mnormalize)\n\u001b[1;32m    217\u001b[0m rescale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiam_mean \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39marray(diams)\n\u001b[1;32m    218\u001b[0m diameter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/models.py:923\u001b[0m, in \u001b[0;36mSizeModel.eval\u001b[0;34m(self, x, channels, channel_axis, normalize, invert, augment, tile, batch_size, progress, interp)\u001b[0m\n\u001b[1;32m    920\u001b[0m diam_style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size_estimation(np\u001b[39m.\u001b[39marray(styles))\n\u001b[1;32m    921\u001b[0m diam_style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiam_mean \u001b[39mif\u001b[39;00m (diam_style\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misnan(diam_style)) \u001b[39melse\u001b[39;00m diam_style\n\u001b[0;32m--> 923\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcp\u001b[39m.\u001b[39;49meval(x, \n\u001b[1;32m    924\u001b[0m                      compute_masks\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    925\u001b[0m                      channels\u001b[39m=\u001b[39;49mchannels, \n\u001b[1;32m    926\u001b[0m                      channel_axis\u001b[39m=\u001b[39;49mchannel_axis, \n\u001b[1;32m    927\u001b[0m                      normalize\u001b[39m=\u001b[39;49mnormalize, \n\u001b[1;32m    928\u001b[0m                      invert\u001b[39m=\u001b[39;49minvert, \n\u001b[1;32m    929\u001b[0m                      augment\u001b[39m=\u001b[39;49maugment, \n\u001b[1;32m    930\u001b[0m                      tile\u001b[39m=\u001b[39;49mtile,\n\u001b[1;32m    931\u001b[0m                      batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m    932\u001b[0m                      net_avg\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    933\u001b[0m                      resample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    934\u001b[0m                      rescale \u001b[39m=\u001b[39;49m  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiam_mean \u001b[39m/\u001b[39;49m diam_style \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiam_mean\u001b[39m>\u001b[39;49m\u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m1\u001b[39;49m, \n\u001b[1;32m    935\u001b[0m                      \u001b[39m#flow_threshold=0,\u001b[39;49;00m\n\u001b[1;32m    936\u001b[0m                      diameter\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    937\u001b[0m                      interp\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    938\u001b[0m                     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    940\u001b[0m diam \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdiameters(masks)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    941\u001b[0m diam \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiam_mean \u001b[39mif\u001b[39;00m (diam\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misnan(diam)) \u001b[39melse\u001b[39;00m diam\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/models.py:551\u001b[0m, in \u001b[0;36mCellposeModel.eval\u001b[0;34m(self, x, batch_size, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, do_3D, anisotropy, net_avg, augment, tile, tile_overlap, resample, interp, flow_threshold, cellprob_threshold, compute_masks, min_size, stitch_threshold, progress, loop_run, model_loaded)\u001b[0m\n\u001b[1;32m    548\u001b[0m     diameter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiam_labels\n\u001b[1;32m    549\u001b[0m     rescale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiam_mean \u001b[39m/\u001b[39m diameter\n\u001b[0;32m--> 551\u001b[0m masks, styles, dP, cellprob, p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_cp(x, \n\u001b[1;32m    552\u001b[0m                                               compute_masks\u001b[39m=\u001b[39;49mcompute_masks,\n\u001b[1;32m    553\u001b[0m                                               normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[1;32m    554\u001b[0m                                               invert\u001b[39m=\u001b[39;49minvert,\n\u001b[1;32m    555\u001b[0m                                               rescale\u001b[39m=\u001b[39;49mrescale, \n\u001b[1;32m    556\u001b[0m                                               net_avg\u001b[39m=\u001b[39;49mnet_avg, \n\u001b[1;32m    557\u001b[0m                                               resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m    558\u001b[0m                                               augment\u001b[39m=\u001b[39;49maugment, \n\u001b[1;32m    559\u001b[0m                                               tile\u001b[39m=\u001b[39;49mtile, \n\u001b[1;32m    560\u001b[0m                                               tile_overlap\u001b[39m=\u001b[39;49mtile_overlap,\n\u001b[1;32m    561\u001b[0m                                               flow_threshold\u001b[39m=\u001b[39;49mflow_threshold,\n\u001b[1;32m    562\u001b[0m                                               cellprob_threshold\u001b[39m=\u001b[39;49mcellprob_threshold, \n\u001b[1;32m    563\u001b[0m                                               interp\u001b[39m=\u001b[39;49minterp,\n\u001b[1;32m    564\u001b[0m                                               min_size\u001b[39m=\u001b[39;49mmin_size, \n\u001b[1;32m    565\u001b[0m                                               do_3D\u001b[39m=\u001b[39;49mdo_3D, \n\u001b[1;32m    566\u001b[0m                                               anisotropy\u001b[39m=\u001b[39;49manisotropy,\n\u001b[1;32m    567\u001b[0m                                               stitch_threshold\u001b[39m=\u001b[39;49mstitch_threshold,\n\u001b[1;32m    568\u001b[0m                                               )\n\u001b[1;32m    570\u001b[0m flows \u001b[39m=\u001b[39m [plot\u001b[39m.\u001b[39mdx_to_circ(dP), dP, cellprob, p]\n\u001b[1;32m    571\u001b[0m \u001b[39mreturn\u001b[39;00m masks, flows, styles\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/models.py:615\u001b[0m, in \u001b[0;36mCellposeModel._run_cp\u001b[0;34m(self, x, compute_masks, normalize, invert, rescale, net_avg, resample, augment, tile, tile_overlap, cellprob_threshold, flow_threshold, min_size, interp, anisotropy, do_3D, stitch_threshold)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m rescale \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m    614\u001b[0m     img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mresize_image(img, rsz\u001b[39m=\u001b[39mrescale)\n\u001b[0;32m--> 615\u001b[0m yf, style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_nets(img, net_avg\u001b[39m=\u001b[39;49mnet_avg,\n\u001b[1;32m    616\u001b[0m                            augment\u001b[39m=\u001b[39;49maugment, tile\u001b[39m=\u001b[39;49mtile,\n\u001b[1;32m    617\u001b[0m                            tile_overlap\u001b[39m=\u001b[39;49mtile_overlap)\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m resample:\n\u001b[1;32m    619\u001b[0m     yf \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mresize_image(yf, shape[\u001b[39m1\u001b[39m], shape[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/core.py:345\u001b[0m, in \u001b[0;36mUnetModel._run_nets\u001b[0;34m(self, img, net_avg, augment, tile, tile_overlap, bsize, return_conv, progress)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m\"\"\" run network (if more than one, loop over networks and average results\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m net_avg:  \n\u001b[0;32m--> 345\u001b[0m     y, style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_net(img, augment\u001b[39m=\u001b[39;49maugment, tile\u001b[39m=\u001b[39;49mtile, tile_overlap\u001b[39m=\u001b[39;49mtile_overlap,\n\u001b[1;32m    346\u001b[0m                              bsize\u001b[39m=\u001b[39;49mbsize, return_conv\u001b[39m=\u001b[39;49mreturn_conv)\n\u001b[1;32m    347\u001b[0m \u001b[39melse\u001b[39;00m:  \n\u001b[1;32m    348\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretrained_model)):\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/core.py:424\u001b[0m, in \u001b[0;36mUnetModel._run_net\u001b[0;34m(self, imgs, augment, tile, tile_overlap, bsize, return_conv)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m# run network\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m tile \u001b[39mor\u001b[39;00m augment \u001b[39mor\u001b[39;00m imgs\u001b[39m.\u001b[39mndim\u001b[39m==\u001b[39m\u001b[39m4\u001b[39m:\n\u001b[0;32m--> 424\u001b[0m     y, style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_tiled(imgs, augment\u001b[39m=\u001b[39;49maugment, bsize\u001b[39m=\u001b[39;49mbsize, \n\u001b[1;32m    425\u001b[0m                               tile_overlap\u001b[39m=\u001b[39;49mtile_overlap, \n\u001b[1;32m    426\u001b[0m                               return_conv\u001b[39m=\u001b[39;49mreturn_conv)\n\u001b[1;32m    427\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(imgs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mitocheck_data2/lib/python3.8/site-packages/cellpose/core.py:526\u001b[0m, in \u001b[0;36mUnetModel._run_tiled\u001b[0;34m(self, imgi, augment, bsize, tile_overlap, return_conv)\u001b[0m\n\u001b[1;32m    524\u001b[0m irange \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(batch_size\u001b[39m*\u001b[39mk, \u001b[39mmin\u001b[39m(IMG\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], batch_size\u001b[39m*\u001b[39mk\u001b[39m+\u001b[39mbatch_size))\n\u001b[1;32m    525\u001b[0m y0, style \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(IMG[irange], return_conv\u001b[39m=\u001b[39mreturn_conv)\n\u001b[0;32m--> 526\u001b[0m y[irange] \u001b[39m=\u001b[39m y0\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(irange), y0\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m], y0\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], y0\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m k\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m    528\u001b[0m     styles \u001b[39m=\u001b[39m style[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load_path = pathlib.Path(\"../1.preprocess_data/labeled_frames_preprocessed/\")\n",
    "features_path = pathlib.Path(\"features/\")\n",
    "training_set_dat_path = pathlib.Path(\"../0.download_data/trainingset.dat\")\n",
    "save_path = pathlib.Path(\"segmented/\")\n",
    "cellpose_model = models.Cellpose(gpu=True, model_type='cyto')\n",
    "segment_training_data(load_path, features_path, training_set_dat_path, save_path, cellpose_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mitocheck_data2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0971d304d530f8782ddf884fa144d2d323dae9a36a62ac6f739c483391c02eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
